{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9a2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# Without feature extraction. \n",
    "################################################################################################\n",
    "\n",
    "\n",
    "###############################\n",
    "#  cla = '1' or '2' response: speed  > 200\n",
    "###############################\n",
    "cla = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a85db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision \n",
    "from torch.utils import data as D\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df78e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "# preparation.\n",
    "######################################################################################################################################################\n",
    "\n",
    "# ############################################################################################\n",
    "# # Extract directory addresses of the img and label files\n",
    "# ############################################################################################\n",
    "class DConfig(object):\n",
    "    parent_folder = './data/compcars/data/label/'\n",
    "    attri = './data/compcars/data/misc/attributes.txt'\n",
    "\n",
    "op = DConfig()\n",
    "# obtain the file addressess in a folder\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70827b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################################################################\n",
    "# # Read the attribute file and drop the lines with missing 'speed'\n",
    "# ############################################################################################\n",
    "attriArray = np.empty((0, 6))\n",
    "with open(op.attri, newline='\\n') as trainfile:\n",
    "    for line in trainfile:\n",
    "        line3 = line.replace(\"\\n\",\"\")\n",
    "        line4 = line3.split(' ')\n",
    "        attriArray = np.concatenate((attriArray, np.array(line4).reshape(1,-1)), axis = 0)\n",
    "\n",
    "attriArray = attriArray[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50dea2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Read the stored dataset\n",
    "########################\n",
    "infile = open('subsetRes4.p', 'rb')\n",
    "subsetRes = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "labelArray_label1 = subsetRes['labelArray_label1']\n",
    "labelArray_label3 = subsetRes['labelArray_label3']\n",
    "labelArray_label2 = subsetRes['labelArray_label2']\n",
    "\n",
    "\n",
    "if cla == '1':\n",
    "    labelArray4 = labelArray_label1\n",
    "elif cla == '3':\n",
    "    labelArray4 = labelArray_label3\n",
    "elif cla == '2':\n",
    "    labelArray4 = labelArray_label2\n",
    "else:\n",
    "    print('error')\n",
    "    \n",
    "########################\n",
    "# the response label is whether the max speed of the car is larger than 'sped'\n",
    "########################\n",
    "sped = 200\n",
    "\n",
    "group1Ind = np.where(labelArray4[:,5] > sped)[0]\n",
    "group2Ind = np.where(labelArray4[:,5] <= sped)[0]\n",
    "\n",
    "########################\n",
    "# split the image indices into training and validation\n",
    "########################\n",
    "np.random.seed(10)\n",
    "shuffleInd1 = np.arange(group1Ind.shape[0])\n",
    "np.random.shuffle(shuffleInd1)\n",
    "\n",
    "shuffleInd2 = np.arange(group2Ind.shape[0])\n",
    "np.random.shuffle(shuffleInd2)\n",
    "\n",
    "halfNum1 = round(shuffleInd1.shape[0]/2)\n",
    "group1IndTrain, group1IndVal = group1Ind[shuffleInd1[:halfNum1]], group1Ind[shuffleInd1[halfNum1]:]\n",
    "\n",
    "halfNum2 = round(shuffleInd2.shape[0]/2)\n",
    "group2IndTrain, group2IndVal = group2Ind[shuffleInd2[:halfNum2]], group2Ind[shuffleInd2[halfNum2]:]\n",
    "\n",
    "# combine the splitted indices for response = 1 and response = 0\n",
    "TrainInd = np.concatenate((group1IndTrain, group2IndTrain))\n",
    "ValInd = np.concatenate((group1IndVal, group2IndVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cae8617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_sizes:  {'train': 1090, 'val': 1875}\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#  Define the dataset object. Apply necessary transform for alexnet\n",
    "###############################\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "    \t# new trial\n",
    "    \t# transforms.RandomPerspective(),\n",
    "        # classical\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "class CompcarsDS(D.Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader.\n",
    "    \"\"\"\n",
    "    def __init__(self, Ind, mode):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "\n",
    "        self.filenames = labelArray4[Ind,3]\n",
    "\n",
    "        self.len = len(self.filenames)\n",
    "        self.transform = data_transforms[mode]\n",
    "                           \n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        image = Image.open(self.filenames[index])\n",
    "        model_id = self.filenames[index].split(\"/\")[6]\n",
    "        # obtain the car speed\n",
    "        label = int(int(attriArray[np.where(attriArray[:,0] == model_id),1][0,0]) > sped)\n",
    "        return self.transform(image), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "\n",
    "\n",
    "# prepare train val datasets and data loaders\n",
    "datTrain = CompcarsDS(Ind = TrainInd, mode = 'train')\n",
    "datVal= CompcarsDS(Ind = ValInd, mode = 'val')\n",
    "\n",
    "image_datasets = {'train': datTrain, 'val': datVal}\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "# Set num_workers=0 to extract raw data.\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print('dataset_sizes: ', dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bbe9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "def export_dataloader_to_csv(dataloader, output_file):\n",
    "    with open(output_file, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            # inputs: (batch_size, 3, 224, 224)\n",
    "            batch_size = inputs.size(0)\n",
    "            inputs_flat = inputs.view(batch_size, -1).numpy()  # shape: (batch_size, 150528)\n",
    "            labels_np = labels.numpy().reshape(-1, 1)  # shape: (batch_size, 1)\n",
    "            batch_data = np.hstack((inputs_flat, labels_np))  # shape: (batch_size, 150529)\n",
    "\n",
    "            writer.writerows(batch_data)\n",
    "\n",
    "# Export train and val\n",
    "export_dataloader_to_csv(dataloaders['train'], \"TrainSpeed_\" + cla + \"without_feature_extraction.csv\")\n",
    "export_dataloader_to_csv(dataloaders['val'], \"ValSpeed_\" + cla + \"without_feature_extraction.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEU1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
